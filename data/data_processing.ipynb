{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "X47TUKhreIHa",
      "metadata": {
        "id": "X47TUKhreIHa"
      },
      "source": [
        "# Preparing, Cleaning, and Merging the Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b8ff51",
      "metadata": {},
      "source": [
        "## Download data\n",
        "### Warning! The below cells will download 321 MB to your machine.\n",
        "\n",
        "The data is sourced from [this page](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.2024.html) on the Census bureau's website.\n",
        "\n",
        "If you examine the data yourself, make sure you use the data under \"Data and Documents\", not under \"Replicate Weight Data and Documents\".\n",
        "\n",
        "2014 Data - Uses Redesigned ASCII Data File & Data Dictionary\n",
        "2015 thru 2018 - Uses ASCII Data File & Data Dictionary\n",
        "2019 thru 2024 - Uses ASCII Data File & Household, Family, and Person Text Layouts (codex/data dictionary text file in previous years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13677af6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, os\n",
        "\n",
        "# Generate directories\n",
        "os.makedirs('input/', exist_ok=True)\n",
        "os.makedirs('output/', exist_ok=True)\n",
        "os.makedirs('output/codex/', exist_ok=True)\n",
        "os.makedirs('output/fwf/', exist_ok=True)\n",
        "os.makedirs('output/merged/', exist_ok=True)\n",
        "\n",
        "def get_file(url, file_path):\n",
        "    print(f\"Fetching from {url}\")\n",
        "    r = requests.get(url)\n",
        "    \n",
        "    data = r.content\n",
        "    \n",
        "    # Skip file if it already exists with same data length\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'rb') as f:\n",
        "            if len(data) == len(f.read()):\n",
        "                print(\"Already exists! Skipping...\")\n",
        "                return\n",
        "\n",
        "    with open(file_path, 'wb+') as f:\n",
        "        print(f\"Writing {len(data)} bytes to {file_path}\")\n",
        "        f.write(data)\n",
        "    print(f\"Saved to {file_path}\")\n",
        "\n",
        "# Download 2014 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2014/march/asec2014_pubuse_3x8_rerun_v2.zip', 'input/2014_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2014/march/asec2014R_pubuse.dd.txt', 'input/2014_codex.txt')\n",
        "\n",
        "# Download 2015 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2015/march/asec2015_pubuse.zip', 'input/2015_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2015/march/asec2015early_pubuse.dd.txt', 'input/2015_codex.txt')\n",
        "\n",
        "# Download 2016 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2015/march/asec2015_pubuse.zip', 'input/2016_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2016/march/Asec2016_Data_Dict_Full.txt', 'input/2016_codex.txt')\n",
        "\n",
        "# Download 2017 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2017/march/asec2017_pubuse.zip', 'input/2017_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2017/march/08ASEC2017_Data_Dict_Full.txt', 'input/2017_codex.txt')\n",
        "\n",
        "# Download 2018 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2018/march/asec2018_pubuse.zip', 'input/2018_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2018/march/08ASEC2018_Data_Dict_Full.txt', 'input/2018_codex.txt')\n",
        "\n",
        "# Download 2019 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2019/march/asec2019_pubuse.zip', 'input/2019_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2019/march/hhldfmt.txt', 'output/codex/2019_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2019/march/famlfmt.txt', 'output/codex/2019_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2019/march/persfmt.txt', 'output/codex/2019_persfmt.txt')\n",
        "\n",
        "# Download 2020 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2020/march/asec2020_pubuse.zip', 'input/2020_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2020/march/hhldfmt.txt', 'output/codex/2020_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2020/march/famlfmt.txt', 'output/codex/2020_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2020/march/persfmt.txt', 'output/codex/2020_persfmt.txt')\n",
        "\n",
        "# Download 2021 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2021/march/asec2021_pubuse.zip', 'input/2021_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2021/march/hhldfmt.txt', 'output/codex/2021_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2021/march/famlfmt.txt', 'output/codex/2021_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2021/march/persfmt.txt', 'output/codex/2021_persfmt.txt')\n",
        "\n",
        "# Download 2022 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2022/march/asec2022_pubuse.zip', 'input/2022_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2022/march/hhldfmt.txt', 'output/codex/2022_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2022/march/famlfmt.txt', 'output/codex/2022_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2022/march/persfmt.txt', 'output/codex/2022_persfmt.txt')\n",
        "\n",
        "# Download 2023 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2023/march/asec2023_pubuse.zip', 'input/2023_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2023/march/hhldfmt.txt', 'output/codex/2023_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2023/march/famlfmt.txt', 'output/codex/2023_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2023/march/persfmt.txt', 'output/codex/2023_persfmt.txt')\n",
        "\n",
        "# Download 2024 FWF DAT and codex files\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2024/march/asec2024_pubuse.zip', 'input/2024_data.zip')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2024/march/hhldfmt.txt', 'output/codex/2024_hhldfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2024/march/famlfmt.txt', 'output/codex/2024_famlfmt.txt')\n",
        "get_file('https://www2.census.gov/programs-surveys/cps/datasets/2024/march/persfmt.txt', 'output/codex/2024_persfmt.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab2af5f",
      "metadata": {},
      "source": [
        "## Unzip data files\n",
        "### Warning! On top of the 321 MB downloaded in the last step, this cell will extract an additional 3.3 GB from the zip archives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fcea269",
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "for year in range(2014, 2025):\n",
        "    try:\n",
        "        with zipfile.ZipFile(f'input/{year}_data.zip', 'r') as zip_file:\n",
        "            data_file = zip_file.filelist[0]\n",
        "            data_file.filename = f'{year}_data.DAT'\n",
        "            print(f\"Extracting and decompressing {data_file.file_size} bytes of data from {year}_data.zip\")\n",
        "            zip_file.extract(data_file, \"output/fwf\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Zip file 'input/{year}_data.zip' not found.\")\n",
        "    except zipfile.BadZipFile:\n",
        "         print(f\"Error: 'input/{year}_data.zip' is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efiYEVjTeZbW",
      "metadata": {
        "id": "efiYEVjTeZbW"
      },
      "source": [
        "## Converting fixed-width files to Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "cuNM7cuheXB5",
      "metadata": {
        "id": "cuNM7cuheXB5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import re\n",
        "\n",
        "### Set up functions to convert and split each .dat file (for the years 2014, 2015, 2016, 2018) into 2 separate dataframes (one for each record type:\n",
        " ## Family, Person)\n",
        " ## *Household record will not be used in this project\n",
        "\n",
        "### Extract these columns only\n",
        "\n",
        "FAMILY_NUMERIC_COLS = ['FFPOS', 'FH-SEQ', 'FPERSONS', 'FPOVCUT', 'FAMLIS', 'POVLL', 'FTOTVAL', 'FEARNVAL']\n",
        "PERSON_NUMERIC_COLS = ['PERIDNUM', 'PF-SEQ', 'PH-SEQ', 'A-AGE', 'PEAFEVER', 'A-HGA', 'A-MJOCC', 'PEARNVAL', 'WSAL-VAL', 'DIV-VAL', 'RTM-VAL']\n",
        "\n",
        "### Splits data dictionary into 3 separate data dictionaries by record type\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def split_dictionary_by_record(input_path, year):\n",
        "    with open(input_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    record_sections = {'HOUSEHOLD RECORD': [], 'FAMILY RECORD': [], 'PERSON RECORD': []}\n",
        "    current_section = None\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line in record_sections:\n",
        "            current_section = line\n",
        "        elif current_section:\n",
        "            record_sections[current_section].append(line + '\\n')\n",
        "\n",
        "    with open(f'output/codex/{year}_hhldfmt.txt', 'w+') as f:\n",
        "        f.writelines(record_sections['HOUSEHOLD RECORD'])\n",
        "    with open(f'output/codex/{year}_famlfmt.txt', 'w+') as f:\n",
        "        f.writelines(record_sections['FAMILY RECORD'])\n",
        "    with open(f'output/codex/{year}_persfmt.txt', 'w+') as f:\n",
        "        f.writelines(record_sections['PERSON RECORD'])\n",
        "\n",
        "### Helper function: matches appropriate record location from the data dictionary based on each column to be extracted\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def extract_layout_from_dict(file_path, features, pattern):\n",
        "    layout = []\n",
        "    feature_set = set(features)\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            match = re.match(pattern, line)\n",
        "            if match:\n",
        "                name, size, start = match.groups()\n",
        "                if name in feature_set:\n",
        "                    size = int(size)\n",
        "                    start = int(start) - 1  # Adjusted for 0-based indexing\n",
        "                    end = start + size\n",
        "                    layout.append((name, start, end))\n",
        "    return layout\n",
        "\n",
        "### Helper function: decodes .fwf format to dataframe using the extracted layout\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def parse_record_lines(lines, layout, numeric_cols):\n",
        "    colspecs = [(start, end) for (_, start, end) in layout]\n",
        "    names = [name for (name, _, _) in layout]\n",
        "    df = pd.read_fwf(StringIO(''.join(lines)), colspecs=colspecs, names=names)\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "### Takes .fwf file and data dictionaries (split by record) as input, and outputs respective dataframes\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def parse_asec_fixed_width(filepath, family_dict_path, person_dict_path, family_cols, person_cols, pattern):\n",
        "    family_layout = extract_layout_from_dict(family_dict_path, family_cols, pattern)\n",
        "    person_layout = extract_layout_from_dict(person_dict_path, person_cols, pattern)\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        lines = [line for line in f if not line.startswith('*')]\n",
        "\n",
        "    # Split by record type\n",
        "    family_lines = [line for line in lines if line.startswith('2')]\n",
        "    person_lines = [line for line in lines if line.startswith('3')]\n",
        "\n",
        "    fam_df = parse_record_lines(family_lines, family_layout, family_cols)\n",
        "    person_df = parse_record_lines(person_lines, person_layout, person_cols)\n",
        "\n",
        "    return fam_df, person_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wBsEA_QRh8qb",
      "metadata": {
        "id": "wBsEA_QRh8qb"
      },
      "outputs": [],
      "source": [
        "# Convert and load dataframes from fixed-width files\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "dataframes = {}\n",
        "\n",
        "family_cols_2014 = ['FFPOS', 'FH-SEQ', 'FPERSONS',\n",
        "                    'FPOVCUT', 'FAMLIS', 'POVLL', 'FTOTVAL', 'FEARNVAL']\n",
        "person_cols_2014 = ['PERIDNUM', 'PF-SEQ', 'PH-SEQ', 'A-AGE', 'PEAFEVER',\n",
        "                    'A-HGA', 'A-MJOCC', 'PEARNVAL', 'WSAL-VAL', 'DIV-VAL', 'RTM-VAL']\n",
        "\n",
        "# 2014 data needs a different column mapping so it is handled separately\n",
        "print(\"Processing 2014 data to DataFrame...\")\n",
        "split_dictionary_by_record(f'input/2014_codex.txt', '2014')\n",
        "dataframes['2014'] = {}\n",
        "dataframes['2014']['fam'], dataframes['2014']['per'] = parse_asec_fixed_width(\n",
        "    'output/fwf/2014_data.DAT', 'output/codex/2014_famlfmt.txt', f'output/codex/2014_persfmt.txt', family_cols_2014, person_cols_2014, r\"D\\s+([\\w-]+)\\s+(\\d+)\\s+(\\d+)\")\n",
        "\n",
        "# Replace hyphens in 2014 columns with underscores\n",
        "dataframes['2014']['fam'].rename(columns={'FH-SEQ': 'FH_SEQ'}, inplace=True)\n",
        "dataframes['2014']['per'].rename(columns={'PF-SEQ': 'PF_SEQ', 'A-AGE': 'A_AGE', 'A-HGA': 'A_HGA', 'A-MJOCC': 'A_MJOCC', 'PH-SEQ': 'PH_SEQ', 'DIV-VAL': 'DIV_VAL', 'RTM-VAL': 'RTM_VAL', 'WSAL-VAL': 'WSAL_VAL'}, inplace=True)\n",
        "dataframes['2014']['per']['CAP_VAL'] = np.nan\n",
        "dataframes['2014']['per']['YEAR'] = 2014\n",
        "dataframes['2014']['fam']['YEAR'] = 2014\n",
        "\n",
        "\n",
        "# after 2014 they use underscores instead of hyphens\n",
        "family_cols = ['FFPOS', 'FH_SEQ', 'FPERSONS',\n",
        "               'FPOVCUT', 'FAMLIS', 'POVLL', 'FTOTVAL', 'FEARNVAL']\n",
        "person_cols = ['PERIDNUM', 'PF_SEQ', 'PH_SEQ', 'A_AGE', 'PEAFEVER',\n",
        "               'A_HGA', 'A_MJOCC', 'PEARNVAL', 'WSAL_VAL', 'DIV_VAL', 'RTM_VAL']\n",
        "\n",
        "# can automate for 2015-2018 as they are all formatted the same\n",
        "for year in ['2015', '2016', '2017', '2018']:\n",
        "    print(f\"Processing {year} data to DataFrame...\")\n",
        "    split_dictionary_by_record(f'input/{year}_codex.txt', year)\n",
        "    dataframes[year] = {}\n",
        "    dataframes[year]['fam'], dataframes[year]['per'] = parse_asec_fixed_width(\n",
        "        f'output/fwf/{year}_data.DAT', f'output/codex/{year}_famlfmt.txt', f'output/codex/{year}_persfmt.txt', family_cols, person_cols, r\"D\\s+([\\w-]+)\\s+(\\d+)\\s+(\\d+)\")\n",
        "    \n",
        "    dataframes[year]['per']['CAP_VAL'] = np.nan\n",
        "    dataframes[year]['per']['YEAR'] = int(year)\n",
        "    dataframes[year]['fam']['YEAR'] = int(year)\n",
        "\n",
        "# 2019-2024 uses a different format codex and doesn't need to be split\n",
        "\n",
        "# 2019-2024 split RTM_VAL into ANN_VAL and DBTN_VAL; additionally added CAP_VAL which we are interested in.\n",
        "person_cols_split_retirement = ['PERIDNUM', 'PF_SEQ', 'PH_SEQ', 'A_AGE', 'PEAFEVER',\n",
        "                                'A_HGA', 'A_MJOCC', 'PEARNVAL', 'WSAL_VAL', 'DIV_VAL', 'CAP_VAL', 'ANN_VAL', 'DBTN_VAL']\n",
        "\n",
        "new_years = ['2019', '2020', '2021', '2022', '2023', '2024']\n",
        "for year in new_years:\n",
        "    print(f\"Processing {year} data to DataFrame...\")\n",
        "    dataframes[year] = {}\n",
        "    dataframes[year]['fam'], dataframes[year]['per'] = parse_asec_fixed_width(\n",
        "        f'output/fwf/{year}_data.DAT', f'output/codex/{year}_famlfmt.txt', f'output/codex/{year}_persfmt.txt', family_cols, person_cols_split_retirement, r\"([\\w-]+)\\s+(\\d+)\\s+(\\d+)\")\n",
        "    \n",
        "    # set RTM_VAL equal to ANN_VAL + DBTN_VAL\n",
        "    dataframes[year]['per']['RTM_VAL'] = dataframes[year]['per']['ANN_VAL'] + dataframes[year]['per']['DBTN_VAL']\n",
        "    dataframes[year]['per'] = dataframes[year]['per'][['PERIDNUM', 'PF_SEQ', 'PH_SEQ', 'A_AGE', 'PEAFEVER', 'A_HGA', 'A_MJOCC', 'PEARNVAL', 'WSAL_VAL', 'CAP_VAL', 'DIV_VAL', 'RTM_VAL']]\n",
        "    \n",
        "    # add YEAR to dataframe\n",
        "    dataframes[year]['per']['YEAR'] = int(year)\n",
        "    dataframes[year]['fam']['YEAR'] = int(year)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "csycYSe1pKg0",
      "metadata": {
        "id": "csycYSe1pKg0"
      },
      "source": [
        "## Merging all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "2y6CfO3TpJOK",
      "metadata": {
        "id": "2y6CfO3TpJOK"
      },
      "outputs": [],
      "source": [
        "all_fam_dfs = []\n",
        "all_per_dfs = []\n",
        "\n",
        "for year in dataframes:\n",
        "    all_fam_dfs.append(dataframes[year]['fam'])\n",
        "    all_per_dfs.append(dataframes[year]['per'])\n",
        "\n",
        "# Concatenate all dataframes by record\n",
        "merged_fam = pd.concat(all_fam_dfs, ignore_index=True)\n",
        "merged_per = pd.concat(all_per_dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ec1b06",
      "metadata": {},
      "source": [
        "## Add Pew research center income classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "id": "59fKI5Bwpnzr",
      "metadata": {
        "id": "59fKI5Bwpnzr"
      },
      "outputs": [],
      "source": [
        "def classify_income_group(df):\n",
        "    income_classes = []\n",
        "\n",
        "    for year in df['YEAR'].unique():\n",
        "        year_data = df[df['YEAR'] == year]\n",
        "        median_income = year_data['ADJUSTED_INC'].median()\n",
        "\n",
        "        # Define ranges (based on Pew logic)\n",
        "        lower = year_data['ADJUSTED_INC'] < 0.67 * median_income\n",
        "        middle = (year_data['ADJUSTED_INC'] >= 0.67 * median_income) & (year_data['ADJUSTED_INC'] <= 2 * median_income)\n",
        "        upper = year_data['ADJUSTED_INC'] > 2 * median_income\n",
        "\n",
        "        income_group = pd.Series(index=year_data.index, dtype=\"object\")\n",
        "        income_group[lower] = 'Lower'\n",
        "        income_group[middle] = 'Middle'\n",
        "        income_group[upper] = 'Upper'\n",
        "\n",
        "        income_classes.append(income_group)\n",
        "\n",
        "    df['INCOME_CLASS'] = pd.concat(income_classes).sort_index()\n",
        "    return df\n",
        "\n",
        "### Add extra feature aggregates to family record\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "grouped_per = merged_per.groupby(['YEAR', 'PH_SEQ', 'PF_SEQ'])[['CAP_VAL', 'DIV_VAL', 'RTM_VAL']].sum()\n",
        "\n",
        "fam_plus = pd.merge(merged_fam, grouped_per, left_on=['YEAR', 'FH_SEQ', 'FFPOS'], right_on=['YEAR', 'PH_SEQ', 'PF_SEQ'], how='inner')\n",
        "\n",
        "fam_plus.rename(columns = {'CAP_VAL': 'CAP_TOT', 'DIV_VAL': 'DIV_TOT', 'RTM_VAL': 'RTM_TOT'}, inplace = True)\n",
        "fam_plus['ADJUSTED_INC'] = fam_plus['FTOTVAL'] / (fam_plus['FPERSONS'])**.5\n",
        "\n",
        "fam_plus = classify_income_group(fam_plus)\n",
        "\n",
        "### Merging family and person dataframes\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "merged_asec = pd.merge(merged_per, fam_plus, left_on=['YEAR', 'PH_SEQ', 'PF_SEQ'], right_on=['YEAR', 'FH_SEQ', 'FFPOS'], how='inner')\n",
        "\n",
        "first_cols = ['YEAR', 'PH_SEQ', 'PF_SEQ']\n",
        "\n",
        "other_cols = [col for col in merged_asec.columns if col not in first_cols]\n",
        "\n",
        "# Reorder\n",
        "merged_asec = merged_asec[first_cols + other_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16Z_AInrr1Ua",
      "metadata": {
        "id": "16Z_AInrr1Ua"
      },
      "source": [
        "## Save merged dataframe to .csv file for efficient loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "id": "-_DWxfqNqTbO",
      "metadata": {
        "id": "-_DWxfqNqTbO"
      },
      "outputs": [],
      "source": [
        "fam_plus.to_csv('output/merged/merged_fam.csv', index=False)\n",
        "merged_asec.to_csv('output/merged/merged_asec.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
