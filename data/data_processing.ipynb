{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing, Cleaning, and Merging the Datasets"
      ],
      "metadata": {
        "id": "X47TUKhreIHa"
      },
      "id": "X47TUKhreIHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting fixed-width files to Pandas Dataframe"
      ],
      "metadata": {
        "id": "efiYEVjTeZbW"
      },
      "id": "efiYEVjTeZbW"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import re\n",
        "\n",
        "### Set up functions to convert and split each .dat file (for the years 2014, 2015, 2016, 2018) into 2 separate dataframes (one for each record type:\n",
        " ## Family, Person)\n",
        " ## *Household record will not be used in this project\n",
        "\n",
        "FAMILY_LAYOUT = []\n",
        "PERSON_LAYOUT = []\n",
        "\n",
        "### Extract these columns only\n",
        "\n",
        "FAMILY_NUMERIC_COLS = ['FFPOS', 'FH-SEQ', 'FPERSONS', 'FPOVCUT', 'FAMLIS', 'POVLL', 'FTOTVAL', 'FEARNVAL']\n",
        "PERSON_NUMERIC_COLS = ['PERIDNUM', 'PF-SEQ', 'PH-SEQ', 'A-AGE', 'PEAFEVER', 'A-HGA', 'A-MJOCC', 'PEARNVAL', 'WSAL-VAL', 'DIV-VAL', 'RTM-VAL']\n",
        "\n",
        "### Splits data dictionary into 3 separate data dictionaries by record type\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def split_dictionary_by_record(input_path, year):\n",
        "    with open(input_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    record_sections = {'HOUSEHOLD RECORD': [], 'FAMILY RECORD': [], 'PERSON RECORD': []}\n",
        "    current_section = None\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line in record_sections:\n",
        "            current_section = line\n",
        "        elif current_section:\n",
        "            record_sections[current_section].append(line + '\\n')\n",
        "\n",
        "    with open(f'household_dict{year}.txt', 'w') as f:\n",
        "        f.writelines(record_sections['HOUSEHOLD RECORD'])\n",
        "    with open(f'family_dict{year}.txt', 'w') as f:\n",
        "        f.writelines(record_sections['FAMILY RECORD'])\n",
        "    with open(f'person_dict{year}.txt', 'w') as f:\n",
        "        f.writelines(record_sections['PERSON RECORD'])\n",
        "\n",
        "### Helper function: matches appropriate record location from the data dictionary based on each column to be extracted\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def extract_layout_from_dict(file_path, features):\n",
        "    layout = []\n",
        "    feature_set = set(features)\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            match = re.match(r\"D\\s+([\\w-]+)\\s+(\\d+)\\s+(\\d+)\", line)\n",
        "            if match:\n",
        "                name, size, start = match.groups()\n",
        "                if name in feature_set:\n",
        "                    size = int(size)\n",
        "                    start = int(start) - 1  # Adjusted for 0-based indexing\n",
        "                    end = start + size\n",
        "                    layout.append((name, start, end))\n",
        "    return layout\n",
        "\n",
        "### Helper function: decodes .fwf format to dataframe using the extracted layout\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def parse_record_lines(lines, layout, numeric_cols):\n",
        "    colspecs = [(start, end) for (_, start, end) in layout]\n",
        "    names = [name for (name, _, _) in layout]\n",
        "    df = pd.read_fwf(StringIO(''.join(lines)), colspecs=colspecs, names=names)\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "### Takes .fwf file and data dictionaries (split by record) as input, and outputs respective dataframes\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def parse_asec_fixed_width(filepath, family_dict_path, person_dict_path):\n",
        "    global FAMILY_LAYOUT, PERSON_LAYOUT\n",
        "    FAMILY_LAYOUT = extract_layout_from_dict(family_dict_path, FAMILY_NUMERIC_COLS)\n",
        "    PERSON_LAYOUT = extract_layout_from_dict(person_dict_path, PERSON_NUMERIC_COLS)\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        lines = [line for line in f if not line.startswith('*')]\n",
        "\n",
        "    # Split by record type\n",
        "    family_lines = [line for line in lines if line.startswith('2')]\n",
        "    person_lines = [line for line in lines if line.startswith('3')]\n",
        "\n",
        "    fam_df = parse_record_lines(family_lines, FAMILY_LAYOUT, FAMILY_NUMERIC_COLS)\n",
        "    person_df = parse_record_lines(person_lines, PERSON_LAYOUT, PERSON_NUMERIC_COLS)\n",
        "\n",
        "    return fam_df, person_df\n"
      ],
      "metadata": {
        "id": "cuNM7cuheXB5"
      },
      "id": "cuNM7cuheXB5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert and load dataframes for years with fixed-width files\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "fwf_years = ['2014', '2015', '2016', '2018']\n",
        "\n",
        "dataframes = {}\n",
        "\n",
        "for year in fwf_years:\n",
        "    split_dictionary_by_record(f'asec_codex{year}.txt', year)\n",
        "    dataframes[year] = {}\n",
        "    dataframes[year]['fam'], dataframes[year]['per'] = parse_asec_fixed_width(f'asec{year}.dat', f'family_dict{year}.txt', f'person_dict{year}.txt')"
      ],
      "metadata": {
        "id": "wBsEA_QRh8qb"
      },
      "id": "wBsEA_QRh8qb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading .csv files for the remaining years"
      ],
      "metadata": {
        "id": "3SheOiF7mJKm"
      },
      "id": "3SheOiF7mJKm"
    },
    {
      "cell_type": "code",
      "source": [
        "### Load and process remaining years' datasets\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "csv_years = ['2017', '2019', '2020', '2021', '2022', '2023', '2024']\n",
        "\n",
        "for year in csv_years:\n",
        "\n",
        "  dataframes[year] = {}\n",
        "  dataframes[year]['fam'] = pd.read_csv(f'family{year}.csv')\n",
        "  dataframes[year]['per'] = pd.read_csv(f'person{year}.csv')\n",
        "\n",
        "  ### Select relevant columns\n",
        "  dataframes[year]['fam'] = dataframes[year]['fam'][['FFPOS', 'FH_SEQ', 'FPERSONS', 'FPOVCUT', 'FAMLIS', 'POVLL', 'FTOTVAL', 'FEARNVAL']]\n",
        "\n",
        "  ### Create RTM_VAL column to match with fwf datasets\n",
        "  dataframes[year]['per']['RTM_VAL'] = dataframes[year]['per']['ANN_VAL'] + dataframes[year]['per']['DBTN_VAL']\n",
        "  dataframes[year]['per'] = dataframes[year]['per'][['PERIDNUM', 'PF_SEQ', 'PH_SEQ', 'A_AGE', 'PEAFEVER', 'A_HGA', 'A_MJOCC', 'PEARNVAL', 'WSAL_VAL', 'CAP_VAL', 'DIV_VAL', 'RTM_VAL']]\n",
        "\n",
        "  ### Add YEAR column\n",
        "  dataframes[year]['per']['YEAR'] = int(year)\n",
        "  dataframes[year]['fam']['YEAR'] = int(year)\n"
      ],
      "metadata": {
        "id": "OspmLjxdmEAW"
      },
      "id": "OspmLjxdmEAW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Rename columns for consistency\n",
        "dataframes['2014']['fam'].rename(columns={'FH-SEQ': 'FH_SEQ'}, inplace=True)\n",
        "dataframes['2014']['per'].rename(columns={'PF-SEQ': 'PF_SEQ', 'A-AGE': 'A_AGE', 'A-HGA': 'A_HGA', 'A-MJOCC': 'A_MJOCC', 'PH-SEQ': 'PH_SEQ', 'DIV-VAL': 'DIV_VAL', 'RTM-VAL': 'RTM_VAL', 'WSAL-VAL': 'WSAL_VAL'}, inplace=True)"
      ],
      "metadata": {
        "id": "PlDIVxlWo3Fz"
      },
      "id": "PlDIVxlWo3Fz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### add CAP_VAL and YEAR column to fwf dataframes to match\n",
        "for year in fwf_years:\n",
        "  dataframes[year]['per']['CAP_VAL'] = np.nan\n",
        "  dataframes[year]['per']['YEAR'] = int(year)\n",
        "  dataframes[year]['fam']['YEAR'] = int(year)"
      ],
      "metadata": {
        "id": "0kw_CSoPpAzw"
      },
      "id": "0kw_CSoPpAzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging all datasets"
      ],
      "metadata": {
        "id": "csycYSe1pKg0"
      },
      "id": "csycYSe1pKg0"
    },
    {
      "cell_type": "code",
      "source": [
        "all_fam_dfs = []\n",
        "all_per_dfs = []\n",
        "\n",
        "for year, dfs in dataframes.items():\n",
        "    all_fam_dfs.append(dfs['fam'])\n",
        "    all_per_dfs.append(dfs['per'])\n",
        "\n",
        "# Concatenate all dataframes by record\n",
        "merged_fam = pd.concat(all_fam_dfs, ignore_index=True)\n",
        "merged_per = pd.concat(all_per_dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "2y6CfO3TpJOK"
      },
      "id": "2y6CfO3TpJOK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add extra feature aggregates to family record\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "grouped_per = merged_per.groupby(['YEAR', 'PH_SEQ', 'PF_SEQ'])[['CAP_VAL', 'DIV_VAL', 'RTM_VAL']].sum()\n",
        "\n",
        "fam_plus = pd.merge(merged_fam, grouped_per, left_on=['YEAR', 'FH_SEQ', 'FFPOS'], right_on=['YEAR', 'PH_SEQ', 'PF_SEQ'], how='inner')\n",
        "\n",
        "fam_plus.rename(columns = {'CAP_VAL': 'CAP_TOT', 'DIV_VAL': 'DIV_TOT', 'RTM_VAL': 'RTM_TOT'}, inplace = True)\n",
        "fam_plus['ADJUSTED_INC'] = fam_plus['FTOTVAL'] / (fam_plus['FPERSONS'])**.5\n",
        "\n",
        "### Merging family and person dataframes\n",
        " ## ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "merged_asec = pd.merge(merged_per, fam_plus, left_on=['YEAR', 'PH_SEQ', 'PF_SEQ'], right_on=['YEAR', 'FH_SEQ', 'FFPOS'], how='inner')\n",
        "\n",
        "first_cols = ['YEAR', 'PH_SEQ', 'PF_SEQ']\n",
        "\n",
        "other_cols = [col for col in merged_asec.columns if col not in first_cols]\n",
        "\n",
        "# Reorder\n",
        "merged_asec = merged_asec[first_cols + other_cols]"
      ],
      "metadata": {
        "id": "59fKI5Bwpnzr"
      },
      "id": "59fKI5Bwpnzr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save merged dataframe to .csv file for efficient loading"
      ],
      "metadata": {
        "id": "16Z_AInrr1Ua"
      },
      "id": "16Z_AInrr1Ua"
    },
    {
      "cell_type": "code",
      "source": [
        "merged_asec.to_csv('merged_asec.csv', index=False)"
      ],
      "metadata": {
        "id": "-_DWxfqNqTbO"
      },
      "id": "-_DWxfqNqTbO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}